{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90322924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Keys loaded:\n",
      "OpenAI API Key: sk-pr***\n",
      "Tavily API Key: tvly-***\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(\"‚úÖ Keys loaded:\")\n",
    "print(f\"OpenAI API Key: {openai_api_key[:5]}***\")\n",
    "print(f\"Tavily API Key: {tavily_api_key[:5]}***\")\n",
    "\n",
    "openai_client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7d0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown(text: str):\n",
    "    display(Markdown(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc096a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # Import the json module for handling JSON data\n",
    "from typing_extensions import TypedDict  # Import TypedDict for type hinting\n",
    "from agents import function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa01c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a TypedDict for the expected parameters for the Tavily search function\n",
    "# A TypedDict is like a blueprint for a dictionary in Python\n",
    "# It tells Python exactly what keys the dictionary should have and what type of values go with each key.\n",
    "\n",
    "class TavilySearchParams(TypedDict):\n",
    "    query: str         # The search query string\n",
    "    max_results: int   # The maximum number of results to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1704f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function that searches the web using the Tavily API and gives back a short summary of the top results.\n",
    "# Decorate the function as a FunctionTool for OpenAI Agents SDK\n",
    "@function_tool\n",
    "def tavily_search(params: TavilySearchParams) -> str:\n",
    "    \"\"\"\n",
    "    Calls the Tavily API and returns a string summary of top search results.\n",
    "\n",
    "    Args:\n",
    "        params (TavilySearchParams): Dictionary with 'query' (str) and 'max_results' (int).\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string summarizing the top search results, or an error message.\n",
    "    \"\"\"\n",
    "    print(\"Start tavily_search\")\n",
    "    \n",
    "    # The web address (endpoint) for sending search requests to Tavily ( Tavily API endpoint)\n",
    "    url = \"https://api.tavily.com/search\" \n",
    "\n",
    "    # Tell the API that we‚Äôre sending JSON data\n",
    "    headers = {\"Content-Type\": \"application/json\"}  \n",
    "\n",
    "    # What we‚Äôre sending to the API:\n",
    "    # Our secret API key (so Tavily knows it's us)\n",
    "    # The search text (query)\n",
    "    # How many results we want (defaults to 2 if not given)\n",
    "    payload = {\n",
    "        \"api_key\": tavily_api_key,  # Use the Tavily API key from environment\n",
    "        \"query\": params[\"query\"],   # The search query from params\n",
    "        \"max_results\": params.get(\"max_results\", 2),  # Use max_results from params, default to 2 if not provided\n",
    "    }\n",
    "\n",
    "    # Send the search request to Tavily (POST means we‚Äôre sending data)\n",
    "    response = requests.post(url, json = payload, headers = headers) \n",
    "\n",
    "    # Check if the search worked (200 = OK)\n",
    "    if response.status_code == 200:  # If the request was successful\n",
    "        results = response.json().get(\"results\", [])  # Extract the 'results' list from the response JSON\n",
    "        \n",
    "        # Build a summary string with each result's title and content, numbered\n",
    "        summary = \"\\n\".join([f\"{i+1}. {r['title']}: {r['content']}\" for i, r in enumerate(results)])\n",
    "        return summary if summary else \"No relevant results found.\"  # Return summary or fallback message\n",
    "    else:\n",
    "        return f\"Tavily API error: {response.status_code}\"  # Return error message with status code if request failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0776e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add memory to our agent\n",
    "from agents import SQLiteSession\n",
    "session = SQLiteSession(\"live_researcher_practice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2eb80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent created with Tavily tool.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent\n",
    "\n",
    "live_researcher_agent = Agent(name = \"Live Market Researcher\",\n",
    "                             instructions = \"\"\"\n",
    "CONTEXT:\n",
    "You are a world-class market research assistant with access to real-time web search via the tavily_search tool.\n",
    "\n",
    "INSTRUCTION:\n",
    "- Analyze the user's question and determine if recent or real-time information is needed.\n",
    "- If the question involves recent events, news, or product info, always call tavily_search.\n",
    "- Summarize search results clearly and concisely, do not copy-paste.\n",
    "- Always start your answer with: \"üîç According to a web search ‚Ä¶\"\n",
    "\n",
    "INPUT:\n",
    "You will receive a conversation history and the latest user question. Use the full context to inform your response.\n",
    "\n",
    "OUTPUT:\n",
    "Provide a clear, well-structured answer that references the search results when appropriate. If you use tavily_search, integrate the findings into your summary.\n",
    "\"\"\",\n",
    "    model = \"gpt-4.1-mini\",\n",
    "    tools = [tavily_search])\n",
    "\n",
    "print(\"‚úÖ Agent created with Tavily tool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79dbdf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**User:** What are people saying about the new GPT-5 Model?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tavily_search\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ü§ñ Agent‚Äôs Answer\n",
       "üîç According to a web search, the GPT-5 model by OpenAI has received a mixed but generally positive reception with several key highlights:\n",
       "\n",
       "- GPT-5 is recognized for being a strong model in coding, reasoning, and agentic tasks, with configurable reasoning effort and superior tool-use skills. It is positioned as the best model globally for coding, which is particularly important for advancing future models like GPT-6.\n",
       "- The model is considered fast, cost-effective, and available to most users, dominating the price-performance space compared to others.\n",
       "- OpenAI has worked on making GPT-5 more customizable and \"warmer\" in personality, acknowledging that no single model fits all user preferences.\n",
       "- However, some users find the upgrade underwhelming compared to competitors like Anthropic‚Äôs Claude 4/4.1 models, and GPT-5 still struggles with creative writing and some advanced reasoning challenges like ARC-AGI 2.\n",
       "- OpenAI provides different versions like GPT-5.2, GPT-5 mini, and GPT-5 nano to balance performance, speed, and cost efficiency.\n",
       "- There is ongoing emphasis on safety features and steerability to prevent misuse and improve user experience.\n",
       "\n",
       "In summary, GPT-5 is noted for its strengths in coding and efficiency, with improvements in user customization and personality, but some users feel certain aspects remain a challenge compared to the latest models by competitors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents import Runner\n",
    "\n",
    "# First question\n",
    "q1 = \"What are people saying about the new GPT-5 Model?\"\n",
    "\n",
    "print_markdown(f\"**User:** {q1}\")\n",
    "\n",
    "run1 = await Runner.run(\n",
    "    starting_agent = live_researcher_agent,\n",
    "    input = q1,\n",
    "    session = session,\n",
    ")\n",
    "\n",
    "print_markdown(f\"### ü§ñ Agent‚Äôs Answer\\n{run1.final_output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588ea58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
